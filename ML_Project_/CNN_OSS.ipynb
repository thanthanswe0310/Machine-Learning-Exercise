{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "L6RgyKdUGVXD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xlrd as xl\n",
        "from pandas import ExcelWriter\n",
        "from pandas import ExcelFile\n",
        "import pickle, re, json, os, datetime, time\n",
        "\n",
        "import pprint\n",
        "pp = pprint.PrettyPrinter(indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8P74sB5Egbr",
        "outputId": "52ce86b6-5630-4e18-f082-e847c6cd8153"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of corpus: 8536\n"
          ]
        }
      ],
      "source": [
        "## Read the data from the pickle file\n",
        "all_data = pd.read_excel('../data/all_data.xlsx')\n",
        "print(\"Size of corpus: \"+str(len(all_data)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rows containing 'nan':\n",
            "Empty DataFrame\n",
            "Columns: [Text Content, Code]\n",
            "Index: []\n",
            "\n",
            "Number of unique classes: 14\n",
            "Number of unique knowledge types: 14\n",
            "Bug Reproduction\n",
            "Contribution and Commitment\n",
            "Expected Behaviour\n",
            "Future Plan\n",
            "Investigation and Exploration\n",
            "Motivation\n",
            "Observed Bug Behaviour\n",
            "Potential New Issues and Requests\n",
            "Solution Discussion\n",
            "Solution Usage\n",
            "Task Progress\n",
            "Testing\n",
            "Usage\n",
            "Workarounds\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel('../data/all_data.xlsx')\n",
        "\n",
        "# Find rows where the label is 'nan'\n",
        "nan_rows = df[df['Code'].isnull()]\n",
        "\n",
        "# Display the rows containing 'nan'\n",
        "print(\"Rows containing 'nan':\")\n",
        "print(nan_rows)\n",
        "\n",
        "# Drop rows where the label is 'nan'\n",
        "df = df.dropna(subset=['Code'])\n",
        "\n",
        "# Convert the 'Code' column to string\n",
        "df['Code'] = df['Code'].astype(str)\n",
        "\n",
        "# Get the number of unique classes\n",
        "num_classes = df['Code'].nunique()\n",
        "print(\"\\nNumber of unique classes:\", num_classes)\n",
        "\n",
        "# Get the set of all unique knowledge types in the corpus\n",
        "knowledge_types = df['Code'].unique()\n",
        "knowledge_types = np.sort(knowledge_types)  # Sort the unique knowledge types\n",
        "\n",
        "print(\"Number of unique knowledge types:\", len(knowledge_types))\n",
        "\n",
        "# Print each label in a new line\n",
        "for label in knowledge_types:\n",
        "    print(label)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNkx98ELGoUd",
        "outputId": "42a3551d-d622-4b96-daf6-3feeb8dd2584"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique knowledge types: 14\n",
            "[   'Bug Reproduction',\n",
            "    'Contribution and Commitment',\n",
            "    'Expected Behaviour',\n",
            "    'Future Plan',\n",
            "    'Investigation and Exploration',\n",
            "    'Motivation',\n",
            "    'Observed Bug Behaviour',\n",
            "    'Potential New Issues and Requests',\n",
            "    'Solution Discussion',\n",
            "    'Solution Usage',\n",
            "    'Task Progress',\n",
            "    'Testing',\n",
            "    'Usage',\n",
            "    'Workarounds']\n"
          ]
        }
      ],
      "source": [
        "## Get the set of all unique knowledge types in the corpus\n",
        "\n",
        "knowledge_types = list(set(all_data['Code']))\n",
        "knowledge_types = [str(item) for item in knowledge_types]  # Convert all elements to strings\n",
        "print(\"Number of unique knowledge types: \" + str(len(knowledge_types)))\n",
        "knowledge_types.sort()\n",
        "\n",
        "pp.pprint(knowledge_types)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jxc2xC6Gs12",
        "outputId": "f393ed27-3dce-410f-b88f-aebd6ca44cc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of sentences from tensorflowissues: 479\n",
            "Number of sentences from scikit-learnissues: 80\n",
            "Number of sentences from spaCyissues: 52\n",
            "Number of sentences from kerasissues: 320\n",
            "Number of sentences from pandasissues: 416\n"
          ]
        }
      ],
      "source": [
        "projects = ['tensorflow','scikit-learn','spaCy', 'keras', 'pandas']\n",
        "for proj in projects:\n",
        "    print(\"Number of sentences from \"+proj+\"issues: \"+str(len(all_data[all_data.Document.str.contains(proj)])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "yKO3tM4jGv0n",
        "outputId": "00ac7ccc-e15b-4c72-d9a7-0057ab8fad1d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document</th>\n",
              "      <th>Code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Node.js (JavaScript) Wrapper API</td>\n",
              "      <td>Expected Behaviour</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Because JavaScript is Awesome</td>\n",
              "      <td>Motivation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>As quoted from the offical website http://www....</td>\n",
              "      <td>Motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Document                Code\n",
              "0                   Node.js (JavaScript) Wrapper API  Expected Behaviour\n",
              "1                      Because JavaScript is Awesome          Motivation\n",
              "2  As quoted from the offical website http://www....          Motivation"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_data.iloc[0:3]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7Blo_aM8G7_C"
      },
      "source": [
        "Transformation on the data:\n",
        "Drop Full Length\n",
        "Convert begauth which contains values True and False to One Hot Encoding\n",
        "Convert the time-based feature tpos2 to a numeric field."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okskdG85G_MV",
        "outputId": "4ff540ae-34ab-44dc-8bd3-14076dbd7899"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Select only the desired columns\n",
        "transformed_data = all_data[['Document', 'Code']]\n",
        "\n",
        "\n",
        "\n",
        "print('Done')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "bwFm4ailHUNq",
        "outputId": "d9846496-bfff-4130-c63c-468f2862b57a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document</th>\n",
              "      <th>Code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Node.js (JavaScript) Wrapper API</td>\n",
              "      <td>Expected Behaviour</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           Document                Code\n",
              "0  Node.js (JavaScript) Wrapper API  Expected Behaviour"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformed_data.iloc[0:1]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rv88OKF0HdVH"
      },
      "source": [
        "Notice that the field Full Length no longer exists and the field begauth has now been changed to begauth_False and begauth_True.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "k8tVa5UkIcf5"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = transformed_data['Document']\n",
        "y = transformed_data['Code']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlBWHdRzOSvw",
        "outputId": "76513cce-2454-4705-f86d-a2133a748ed5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                   precision    recall  f1-score   support\n",
            "\n",
            "                 Bug Reproduction       0.66      0.54      0.59       148\n",
            "      Contribution and Commitment       0.86      0.84      0.85       170\n",
            "               Expected Behaviour       0.28      0.17      0.21        30\n",
            "                      Future Plan       0.86      0.86      0.86         7\n",
            "    Investigation and Exploration       0.64      0.46      0.53       167\n",
            "                       Motivation       0.51      0.39      0.44        71\n",
            "           Observed Bug Behaviour       0.72      0.40      0.51        90\n",
            "Potential New Issues and Requests       0.42      0.21      0.28        52\n",
            "              Solution Discussion       0.67      0.88      0.76       796\n",
            "                   Solution Usage       0.00      0.00      0.00         4\n",
            "                    Task Progress       0.61      0.37      0.46        30\n",
            "                          Testing       0.75      0.50      0.60         6\n",
            "                            Usage       0.61      0.44      0.51        71\n",
            "                      Workarounds       0.65      0.33      0.44        66\n",
            "\n",
            "                         accuracy                           0.67      1708\n",
            "                        macro avg       0.59      0.46      0.50      1708\n",
            "                     weighted avg       0.66      0.67      0.65      1708\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "X = transformed_data['Document']\n",
        "y = transformed_data['Code']\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10, shuffle=True)\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_tf = vectorizer.fit_transform(X_train)\n",
        "X_test_tf = vectorizer.transform(X_test)\n",
        "\n",
        "clf = LogisticRegression()\n",
        "model = clf.fit(X_train_tf, y_train)\n",
        "y_pred = clf.predict(X_test_tf)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "8o2qhMbyItkX"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "f25iLg04KChb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPDyl17dMHgI",
        "outputId": "284ad20e-e7be-4bea-b792-c0e440909165"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "214/214 [==============================] - 17s 73ms/step - loss: 1.9660 - accuracy: 0.4606 - val_loss: 1.6723 - val_accuracy: 0.5205\n",
            "Epoch 2/10\n",
            "214/214 [==============================] - 15s 72ms/step - loss: 1.5419 - accuracy: 0.5403 - val_loss: 1.4152 - val_accuracy: 0.5861\n",
            "Epoch 3/10\n",
            "214/214 [==============================] - 16s 73ms/step - loss: 1.2003 - accuracy: 0.6325 - val_loss: 1.3303 - val_accuracy: 0.6036\n",
            "Epoch 4/10\n",
            "214/214 [==============================] - 15s 71ms/step - loss: 0.9258 - accuracy: 0.7119 - val_loss: 1.3180 - val_accuracy: 0.6347\n",
            "Epoch 5/10\n",
            "214/214 [==============================] - 15s 71ms/step - loss: 0.7208 - accuracy: 0.7800 - val_loss: 1.4197 - val_accuracy: 0.6563\n",
            "Epoch 6/10\n",
            "214/214 [==============================] - 16s 73ms/step - loss: 0.5501 - accuracy: 0.8382 - val_loss: 1.4722 - val_accuracy: 0.6522\n",
            "Epoch 7/10\n",
            "214/214 [==============================] - 15s 72ms/step - loss: 0.4112 - accuracy: 0.8871 - val_loss: 1.5984 - val_accuracy: 0.6575\n",
            "Epoch 8/10\n",
            "214/214 [==============================] - 15s 71ms/step - loss: 0.3116 - accuracy: 0.9123 - val_loss: 1.7922 - val_accuracy: 0.6628\n",
            "Epoch 9/10\n",
            "214/214 [==============================] - 15s 71ms/step - loss: 0.2320 - accuracy: 0.9405 - val_loss: 1.9259 - val_accuracy: 0.6534\n",
            "Epoch 10/10\n",
            "214/214 [==============================] - 15s 71ms/step - loss: 0.1872 - accuracy: 0.9533 - val_loss: 2.0185 - val_accuracy: 0.6598\n",
            "54/54 [==============================] - 1s 15ms/step\n",
            "Test accuracy: 0.6598360655737705\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Embedding, Conv1D, GlobalMaxPooling1D\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X = transformed_data['Document']\n",
        "y = transformed_data['Code']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10, shuffle=True)\n",
        "\n",
        "# Encode labels as integers\n",
        "le = LabelEncoder()\n",
        "le.fit(y_train)\n",
        "y_train = le.transform(y_train)\n",
        "y_test = le.transform(y_test)\n",
        "\n",
        "# Convert target variables to one-hot encoding\n",
        "num_classes = len(knowledge_types)\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "# Tokenize and pad sequences\n",
        "max_sequence_length = 1000\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_sequence_length)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_sequence_length)\n",
        "\n",
        "# Define the model architecture\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5000, output_dim=50, input_length=max_sequence_length))\n",
        "model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dropout(rate=0.3))\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_pad, y_train, validation_data=(X_test_pad, y_test), epochs=10, batch_size=32)\n",
        "\n",
        "# Evaluate the model on test data\n",
        "y_pred = model.predict(X_test_pad)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "y_test_decoded = np.argmax(y_test, axis=1)\n",
        "accuracy = accuracy_score(y_test_decoded, y_pred)\n",
        "print('Test accuracy:', accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZ9cqpCUXMMz",
        "outputId": "f7e75474-65a7-4210-a707-ca8acf04f8d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "54/54 [==============================] - 1s 15ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.70      0.66       148\n",
            "           1       0.88      0.85      0.87       170\n",
            "           2       0.29      0.23      0.26        30\n",
            "           3       1.00      0.14      0.25         7\n",
            "           4       0.47      0.49      0.48       167\n",
            "           5       0.32      0.46      0.38        71\n",
            "           6       0.56      0.48      0.51        90\n",
            "           7       0.37      0.27      0.31        52\n",
            "           8       0.76      0.79      0.78       796\n",
            "           9       0.00      0.00      0.00         4\n",
            "          10       0.43      0.33      0.38        30\n",
            "          11       0.75      0.50      0.60         6\n",
            "          12       0.56      0.42      0.48        71\n",
            "          13       0.49      0.44      0.46        66\n",
            "\n",
            "    accuracy                           0.66      1708\n",
            "   macro avg       0.54      0.44      0.46      1708\n",
            "weighted avg       0.66      0.66      0.66      1708\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Convert one-hot encoded test labels back to integer labels\n",
        "y_test_int = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Generate predictions for test data\n",
        "y_pred = model.predict(X_test_pad)\n",
        "y_pred_int = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test_int, y_pred_int))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
